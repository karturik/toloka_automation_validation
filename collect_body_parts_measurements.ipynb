{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "import json\n",
    "import decimal\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import traceback\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import toloka.client as toloka\n",
    "\n",
    "import psycopg2\n",
    "from contextlib import closing\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# credentials\n",
    "DB_data = '''\n",
    "    host=host\n",
    "    port=port\n",
    "    sslmode=require\n",
    "    dbname=dbname\n",
    "    user=user\n",
    "    password=password\n",
    "    target_session_attrs=read-write\n",
    "'''\n",
    "\n",
    "e = datetime.now()\n",
    "\n",
    "date = '%s.%s.%s' % (e.day, e.month, e.year)\n",
    "\n",
    "OAUTH_TOKEN = 'OAUTH_TOKEN1'\n",
    "HEADERS = {\"Authorization\": \"OAuth %s\" % OAUTH_TOKEN, \"Content-Type\": \"application/JSON\"}\n",
    "toloka_client = toloka.TolokaClient(OAUTH_TOKEN, 'PRODUCTION')\n",
    "\n",
    "skill_id_reject = 1\n",
    "\n",
    "# to dataframe with processing assignments\n",
    "working_excel = pd.read_excel('working_excel 1.2.xlsx', sheet_name='Sheet1')\n",
    "measurement_df = working_excel.loc[:, 'measurements_english_translate':'measurements_arabian_translate'].dropna()\n",
    "\n",
    "# images names with their order number\n",
    "images_order_dict = {\"1\": \"front_img\", \"2\": \"side_img\", \"3\": \"selfie_img\",\n",
    "                           \"4\": \"arm_circumference_cm\",\n",
    "                           \"5\": \"arm_length_cm\", \"6\": \"back_build_cm\", \"7\": \"calf_circumference_cm\",\n",
    "                           \"8\": \"chest_circumference_cm\", \"9\": \"crotch_height_cm\", \"10\": \"front_build_cm\",\n",
    "                           \"11\": \"hips_circumference_cm\", \"12\": \"leg_length_cm\", \"13\": \"neck_circumference_cm\",\n",
    "                           \"14\": \"neck_pelvis_length_front_cm\", \"15\": \"neck_waist_length_back_cm\",\n",
    "                           \"16\": \"neck_waist_length_front_cm\", \"17\": \"pelvis_circumference_cm\",\n",
    "                           \"18\": \"shoulder_length_cm\", \"19\": \"shoulder_width_cm\",\n",
    "                           \"20\": \"thigh_circumference_cm\", \"21\": \"under_chest_circumference_cm\",\n",
    "                           \"22\": \"upper_arm_length_cm\", \"23\": \"waist_circumference_cm\",\n",
    "                           \"H\": \"height\", \"W\": \"weight\",\n",
    "                           \"A\": \"age\",\"G\": \"gender\",\n",
    "                            \"E\": \"race\", \"P\": \"profession\"\n",
    "                           }\n",
    "\n",
    "# make empty measurement dict\n",
    "measurements_results = {\"front_img\": None, \"side_img\": None, \"selfie_img\": None,\n",
    "                            \"arm_circumference_cm\": None,\n",
    "                           \"arm_length_cm\": None, \"back_build_cm\": None,\n",
    "                            \"calf_circumference_cm\": None, \"chest_circumference_cm\": None,\n",
    "                            \"crotch_height_cm\": None,\"front_build_cm\": None,\n",
    "                           \"hips_circumference_cm\":None, \"leg_length_cm\":None, \"neck_circumference_cm\":None,\n",
    "                           \"neck_pelvis_length_front_cm\": None, \"neck_waist_length_back_cm\": None,\n",
    "                           \"neck_waist_length_front_cm\": None, \"pelvis_circumference_cm\": None,\n",
    "                           \"shoulder_length_cm\": None, \"shoulder_width_cm\": None,\n",
    "                           \"thigh_circumference_cm\": None, \"under_chest_circumference_cm\": None,\n",
    "                           \"upper_arm_length_cm\": None, \"waist_circumference_cm\": None,\n",
    "                           \"height\": None, \"weight\": None,\n",
    "                           \"age\": None, \"gender\": None, \"race\": None}\n",
    "\n",
    "gender_dict = {'F':'female', 'M':'male'}\n",
    "\n",
    "ethnicity_dict = {'I':'indian', 'C':'caucasian', 'B':'black', 'L':'latino', 'A':'asian', 'M':'maghreb', '0':'null'}\n",
    "\n",
    "# query templates\n",
    "download_db_columns = '(assignment_id, worker_id, project_id,' \\\n",
    "                      ' toloka_submit_date, download_date, gender,' \\\n",
    "                      ' age, nation, status, assignment_link)'\n",
    "\n",
    "send_db_columns = '(assignment_id, worker_id, project_id,' \\\n",
    "                  ' toloka_submit_date, download_date, gender,' \\\n",
    "                  ' age, nation, status, send_date, assignment_link)'\n",
    "\n",
    "query_download_insert = ''' INSERT INTO public.sets %s\n",
    "                    VALUES ('%s','%s','%s','%s','%s','%s','%s','%s','DOWNLOADED','%s') '''\n",
    "\n",
    "query_download_update = ''' UPDATE public.sets SET worker_id='%s',\n",
    "                                 project_id='%s', toloka_submit_date='%s',\n",
    "                                  download_date='%s', gender='%s',\n",
    "                                   age='%s', nation='%s', status='DOWNLOADED',\n",
    "                                    assignment_link='%s' WHERE assignment_id ='%s' '''\n",
    "\n",
    "query_send_insert = f''' INSERT INTO public.sets %s\n",
    "                                VALUES ('%s','%s','%s','%s',\n",
    "                                '%s','%s','%s','%s','INWORK', '%s', '%s') '''\n",
    "\n",
    "query_send_update = ''' UPDATE public.sets SET worker_id='%s',\n",
    "                         project_id='%s', toloka_submit_date='%s',\n",
    "                          gender='%s',age='%s', status = 'INWORK',\n",
    "                           assignment_link='%s',nation='%s',\n",
    "                            send_date = '%s' WHERE assignment_id ='%s' '''\n",
    "\n",
    "# get sets from database to dataframe for dublicats checking\n",
    "with closing(psycopg2.connect(DB_data)) as conn:\n",
    "    with closing(conn.cursor()) as cursor:\n",
    "        cursor.execute('''SELECT assignment_id, worker_id, project_id, toloka_submit_date,\n",
    "                                              download_date, gender, age,\n",
    "                                              nation, status, send_date, assignment_link FROM public.sets''')\n",
    "        all_sets_in_db_df = pd.DataFrame(cursor.fetchall(), columns = ['assignment_id', 'worker_id', 'project_id', 'toloka_submit_date',\n",
    "                                              'download_date', 'gender', 'age',\n",
    "                                              'nation', 'status', 'send_date', 'assignment_link'])\n",
    "\n",
    "\n",
    "with open('errors.tsv', 'w', encoding='utf-8') as file:\n",
    "    file.close()\n",
    "\n",
    "with open('need_manual.tsv', 'w', encoding='utf-8') as file:\n",
    "    file.close()\n",
    "\n",
    "def error_writer(request: str) -> None:\n",
    "    with open('errors.tsv', 'a', encoding='utf-8') as file:\n",
    "        file.write('\\n' + request + '\\n' + '*'*50)\n",
    "\n",
    "def need_manual_writer(request: str) -> None:\n",
    "    with open('need_manual.tsv', 'a', encoding='utf-8') as file:\n",
    "        file.write(request + '\\n')\n",
    "\n",
    "#decorator for trying different Toloka tokens\n",
    "def decorator_change_account(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        tries = 0\n",
    "        success = False\n",
    "        while not success or tries < 5:\n",
    "            try:\n",
    "                func(*args, **kwargs)\n",
    "                break\n",
    "            except toloka.exceptions.AccessDeniedApiError:\n",
    "                global OAUTH_TOKEN, HEADERS, toloka_client\n",
    "                if OAUTH_TOKEN == 'OAUTH_TOKEN1':\n",
    "                    OAUTH_TOKEN = 'OAUTH_TOKEN2'\n",
    "                elif OAUTH_TOKEN == 'OAUTH_TOKEN2':\n",
    "                    OAUTH_TOKEN = 'OAUTH_TOKEN1'\n",
    "                HEADERS = {\"Authorization\": \"OAuth %s\" % OAUTH_TOKEN, \"Content-Type\": \"application/JSON\"}\n",
    "                toloka_client = toloka.TolokaClient(OAUTH_TOKEN, 'PRODUCTION')\n",
    "                print('Change Toloka-account')\n",
    "                tries += 1\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# save set to database\n",
    "def db_update(assignment_id: str,\n",
    "              worker_id: str,\n",
    "              project_id: str,\n",
    "              assignment_data: toloka.Assignment,\n",
    "              worker_data: json,\n",
    "              assignment_link: str,\n",
    "              check_working_df: pd.DataFrame) -> None:\n",
    "\n",
    "    toloka_date = assignment_data.created\n",
    "    toloka_submit_date = '%s.%s.%s' % (toloka_date.day, toloka_date.month, toloka_date.year)\n",
    "\n",
    "    dublicate_set = all_sets_in_db_df.loc[all_sets_in_db_df['assignment_id'] == assignment_id]\n",
    "\n",
    "    solution = assignment_data.solutions[0]\n",
    "\n",
    "    age = solution.output_values['age']\n",
    "    if 'A' in check_working_df.dropna(axis=1):\n",
    "        age = str(float(check_working_df.reset_index()['A'][0])).replace('.0', '')\n",
    "\n",
    "    gender = ''\n",
    "    if 'gender' in worker_data:\n",
    "        gender = worker_data['gender']\n",
    "    if 'G' in check_working_df.dropna(axis=1):\n",
    "        gender = gender_dict[check_working_df.reset_index()['G'][0].upper()]\n",
    "\n",
    "    nation = ''\n",
    "    nation = solution.output_values['race']\n",
    "    if 'E' in check_working_df.dropna(axis=1):\n",
    "        nation = ethnicity_dict[check_working_df.reset_index()['E'][0].upper()]\n",
    "\n",
    "    query = ''\n",
    "\n",
    "    scenario_date = date\n",
    "\n",
    "    if '+' in check_working_df.values and not 'send' in check_working_df.values:\n",
    "        print('Update sets status to \"download\"')\n",
    "        if dublicate_set.empty:\n",
    "            query = query_download_insert % (download_db_columns, assignment_id,\n",
    "                                             worker_id, project_id, toloka_submit_date,\n",
    "                                             scenario_date, gender.upper(), age, nation, assignment_link)\n",
    "\n",
    "        else:\n",
    "            query = query_download_update % (worker_id, project_id,\n",
    "                                             toloka_submit_date, scenario_date,\n",
    "                                             gender.upper(), age, nation, assignment_link, assignment_id)\n",
    "\n",
    "            print('There is already set in DB, update its status')\n",
    "\n",
    "\n",
    "    elif 'send' in check_working_df.values:\n",
    "        print('Update sets status to \"send to requester\"')\n",
    "        if dublicate_set.empty:\n",
    "            query = query_send_insert % (send_db_columns, assignment_id,\n",
    "                                         worker_id, project_id, toloka_submit_date,\n",
    "                                         scenario_date, gender.upper(), age, nation, scenario_date, assignment_link)\n",
    "\n",
    "            print('There is no such set, add new')\n",
    "\n",
    "        else:\n",
    "\n",
    "            query = query_send_update % (worker_id, project_id,\n",
    "                                         toloka_submit_date, gender.upper(), age,\n",
    "                                         assignment_link, nation, scenario_date, assignment_id)\n",
    "\n",
    "            print('There is already set in DB, update its status')\n",
    "\n",
    "    try:\n",
    "        with closing(psycopg2.connect(DB_data)) as conn:\n",
    "            with closing(conn.cursor()) as cursor:\n",
    "                cursor.execute(query)\n",
    "                conn.commit()\n",
    "                print('Update data')\n",
    "    except Exception as e:\n",
    "        print('Some error')\n",
    "        error_writer(f'{assignment_id}\\t{e}')\n",
    "\n",
    "# get Assignment data\n",
    "def get_assignment_data(assignment_id: str) -> toloka.Assignment:\n",
    "    assignment_data = toloka_client.get_assignment(assignment_id=assignment_id)\n",
    "    return assignment_data\n",
    "\n",
    "# get Pool data\n",
    "def get_pool_data(pool_id: str) -> toloka.Pool:\n",
    "    pool_data = toloka_client.get_pool(pool_id=pool_id)\n",
    "    return pool_data\n",
    "\n",
    "# get Worker data\n",
    "def get_worker_data(worker_id: str) -> json:\n",
    "    worker_data = requests.get(url='https://toloka.dev/api/new/requester/workers/' + worker_id, headers=HEADERS).json()\n",
    "    return worker_data\n",
    "\n",
    "\n",
    "# skill giving\n",
    "@decorator_change_account\n",
    "def skill_give(assignment_id: str, worker_id: str) -> None:\n",
    "    toloka_client.set_user_skill(skill_id=skill_id_reject, user_id=worker_id, value=decimal.Decimal('100'))\n",
    "    print('Skill added')\n",
    "\n",
    "\n",
    "# send message\n",
    "def message_send(assignment_data: toloka.Assignment,\n",
    "                 reject_message: str,\n",
    "                 reject_topic: str,\n",
    "                 worker_id: str,\n",
    "                 refusal_reassons_column: str,\n",
    "                 check_working_df: pd.DataFrame,\n",
    "                 measurements_translate: dict) -> None:\n",
    "\n",
    "    assignment_id = assignment_data.id\n",
    "    image_and_reject_reason_dict = {}\n",
    "    for image_column_name in check_working_df.dropna(axis=1):\n",
    "        if image_column_name != 'reject_reasons':\n",
    "            image_and_reject_reason_dict[images_order_dict[str(image_column_name)]] = str(check_working_df.reset_index()[image_column_name][0]).split(' ')\n",
    "\n",
    "    reject_reasons_for_html = reject_reasons_for_html_maker(image_and_reject_reason_dict, refusal_reassons_column, measurements_translate)\n",
    "    reject_message = reject_message.replace('{reject_reasons}', reject_reasons_for_html)\n",
    "    message_body = {\n",
    "        \"topic\": {\n",
    "            \"EN\": reject_topic,\n",
    "        },\n",
    "        \"text\": {\n",
    "            \"EN\": reject_message,\n",
    "        },\n",
    "        \"recipients_select_type\": \"DIRECT\",\n",
    "        \"recipients_ids\": [worker_id],\n",
    "        \"answerable\": True\n",
    "    }\n",
    "    send_msg = requests.post('https://toloka.dev/api/v1/message-threads/compose', headers=HEADERS,\n",
    "                             json=message_body).json()\n",
    "\n",
    "    if 'created' in send_msg:\n",
    "        print('Message sended')\n",
    "    else:\n",
    "        print('Some error: ', send_msg)\n",
    "        need_manual_writer(f\"{assignment_id}\\tsend message\\n\")\n",
    "\n",
    "# reject set\n",
    "@decorator_change_account\n",
    "def reject_set(assignment_id: str) -> None:\n",
    "    toloka_client.reject_assignment(assignment_id=assignment_id, public_comment='Have some mistakes')\n",
    "    print('Отклонили сет ', assignment_id)\n",
    "\n",
    "# make html message with reject reasons\n",
    "def reject_reasons_for_html_maker(image_and_reject_reason_dict: dict,\n",
    "                                  refusal_reassons_column: str,\n",
    "                                  measurements_translate: dict) -> str:\n",
    "    reject_reasons_for_html = ''\n",
    "    for key, value in image_and_reject_reason_dict.items():\n",
    "        image_name = measurements_translate[key]\n",
    "        reject_reasons = value\n",
    "        for reject_reason in reject_reasons:\n",
    "            reject_reason_text = working_excel.loc[working_excel['refusal_reasons_number'].apply(float) == float(reject_reason), refusal_reassons_column].values[0]\n",
    "            reject_reason_for_html = '''\n",
    "            <li style=\"margin-top: 0cm; margin-right: 0cm; margin-bottom: 8pt; line-height: normal;\n",
    "             font-size: 15px; font-family: Calibri, sans-serif; background: white;\">\n",
    "             <strong>\n",
    "             <span style='font-size:16px;font-family:\"Arial\",sans-serif;color:#141824;'>''' \\\n",
    "                                     + reject_reason_text + f' ({image_name})' '''</span></strong></li>'''\n",
    "            reject_reasons_for_html += reject_reason_for_html\n",
    "    return reject_reasons_for_html\n",
    "\n",
    "# get assignment_id from assignment_link\n",
    "def get_assignment_id_from_link(assignment_id):\n",
    "    assignment_id = assignment_id.split('assignments/')[1].split('?')[0]\n",
    "    return assignment_id\n",
    "\n",
    "# select worker language\n",
    "def language_select(worker_data) -> [str]:\n",
    "    if 'RU' in worker_data['languages']:\n",
    "        language = 'russian'\n",
    "    elif 'ES' in worker_data['languages']:\n",
    "        language = 'spain'\n",
    "    elif 'FR' in worker_data['languages']:\n",
    "        language = 'france'\n",
    "    elif 'DE' in worker_data['languages']:\n",
    "        language = 'german'\n",
    "    elif 'TR' in worker_data['languages']:\n",
    "        language = 'turkey'\n",
    "    elif 'HI' in worker_data['languages']:\n",
    "        language = 'hindi'\n",
    "    elif 'UR' in worker_data['languages']:\n",
    "        language = 'urdu'\n",
    "    elif 'AR' in worker_data['languages']:\n",
    "        language = 'arabian'\n",
    "    else:\n",
    "        language = 'english'\n",
    "    print('Язык выбран: ', language)\n",
    "    refusal_reassons_column = f'refusal_reasons_text_{language}'\n",
    "    measurement_column = f'measurements_{language}_translate'\n",
    "    reject_topic = working_excel.loc[1, f'reject_message_{language}']\n",
    "    reject_message = working_excel.loc[0, f'reject_message_{language}']\n",
    "\n",
    "    measurements_translate = {}\n",
    "    for key, value in zip(measurement_df['measurements_english_translate'], measurement_df[measurement_column]):\n",
    "        measurements_translate[key] = value\n",
    "\n",
    "    return reject_message, reject_topic, refusal_reassons_column, measurements_translate\n",
    "\n",
    "\n",
    "def insert_validator_data_to_measurements(check_working_df:pd.DataFrame) -> dict:\n",
    "    for column_name in check_working_df.dropna(axis=1):\n",
    "        if column_name != 'reject_reasons':\n",
    "            value = str(check_working_df.reset_index().loc[0, column_name])\n",
    "            if column_name == 'G':\n",
    "                value = gender_dict[value.upper()]\n",
    "            elif column_name == 'E':\n",
    "                value = ethnicity_dict[value.upper()]\n",
    "            elif column_name == 'A':\n",
    "                value = str(float(re.sub(r'[^0-9]', '', value))).replace('.0', '')\n",
    "            if value == '0.0' or value == 0.0 or value == 0 or value == '0':\n",
    "                value = 'null'\n",
    "            measurements_results[images_order_dict[str(column_name)]] = value\n",
    "    return measurements_results\n",
    "\n",
    "\n",
    "def manual_input_some_data(solution, measurements_results: dict, assignment_id: str, param_name: str) -> str:\n",
    "    if not param_name in measurements_results or not measurements_results[param_name]:\n",
    "        data = solution.output_values[param_name]\n",
    "        if not data:\n",
    "            data = input(f'{assignment_id}, {param_name}, need manual edit: ')\n",
    "    else:\n",
    "        data = measurements_results[param_name]\n",
    "    return data\n",
    "\n",
    "\n",
    "# download images\n",
    "def download_images(assignment_data: toloka.Assignment,\n",
    "                    check_working_df:pd.DataFrame) -> None:\n",
    "    assignment_id = assignment_data.id\n",
    "    cur_dir = os.path.join('measurements_sets', date, assignment_id)\n",
    "    if not os.path.exists(cur_dir):\n",
    "        os.makedirs(cur_dir)\n",
    "        measurements_results = insert_validator_data_to_measurements(check_working_df)\n",
    "        photos_keys = []\n",
    "        for solution in assignment_data.solutions:\n",
    "            for key in tqdm(solution.output_values.keys()):\n",
    "                if key[-3:] == 'img':\n",
    "                    photos_keys.append(key)\n",
    "                elif key[-2:] == 'cm' or key == 'weight' or key == 'height':\n",
    "                    img_to_cm_translate = manual_input_some_data(solution, measurements_results, assignment_id, param_name = key)\n",
    "                    measurements_results[key] = str(float(re.sub(r'[^0-9.]', '', img_to_cm_translate)))\n",
    "                elif key == 'race':\n",
    "                    measurements_results[key] = solution.output_values[key]\n",
    "                elif key == 'age':\n",
    "                    measurements_results[key] = str(solution.output_values[key])\n",
    "            for photo_key in photos_keys:\n",
    "                out_f = BytesIO()\n",
    "                toloka_client.download_attachment(attachment_id=solution.output_values[photo_key], out=out_f)\n",
    "                img = Image.open(out_f)\n",
    "                if photo_key != 'front_img' and photo_key != 'side_img' and photo_key != 'selfie_img':\n",
    "                    img_to_cm_translate = measurements_results[photo_key[:-3]+'cm']\n",
    "                    img.save(os.path.join(cur_dir, photo_key + '_' + img_to_cm_translate + '.jpg'))\n",
    "                else:\n",
    "                    img.save(os.path.join(cur_dir, photo_key + '.jpg'))\n",
    "\n",
    "        measurements_results = insert_validator_data_to_measurements(check_working_df)\n",
    "        files_info_json = json.dumps(measurements_results)\n",
    "        print(files_info_json)\n",
    "        with open(os.path.join(cur_dir, 'measurements.json'), 'w') as f:\n",
    "            f.write(files_info_json)\n",
    "\n",
    "    else:\n",
    "        print('Such dir already exists')\n",
    "\n",
    "# check sets for dublicats\n",
    "def predownload_set_dublicat_checking_and_download(assignment_data: toloka.Assignment,\n",
    "                                                   worker_id: str,\n",
    "                                                   check_working_df: pd.DataFrame) -> None:\n",
    "    assignment_id = assignment_data.id\n",
    "    if not assignment_id in all_sets_in_db_df['assignment_id'].unique() and not \\\n",
    "            worker_id in all_sets_in_db_df['worker_id'].unique():\n",
    "        download_images(assignment_data, check_working_df)\n",
    "    else:\n",
    "        same_set_by_id = all_sets_in_db_df.loc[(all_sets_in_db_df['assignment_id'] == assignment_id)]\n",
    "        same_set_by_worker = all_sets_in_db_df.loc[(all_sets_in_db_df['worker_id'] == worker_id)]\n",
    "        if not same_set_by_id.empty:\n",
    "            print('There is already set with this id: ')\n",
    "            print(same_set_by_id.to_markdown())\n",
    "        if not same_set_by_worker.empty:\n",
    "            print('There is already set with this worker: ')\n",
    "            print(same_set_by_worker.to_markdown())\n",
    "        decision = input('Download? \\n 1.Yes \\n 2.No')\n",
    "        if decision == '1':\n",
    "            download_images(assignment_data, check_working_df)\n",
    "        else:\n",
    "            print('Cancel download')\n",
    "\n",
    "\n",
    "def start(assignment_id: str, assignment_cell_in_excel: str) -> None:\n",
    "    assignment_data = get_assignment_data(assignment_id)\n",
    "    pool_data = get_pool_data(pool_id=assignment_data.pool_id)\n",
    "    project_id = pool_data.project_id\n",
    "    worker_id = assignment_data.user_id\n",
    "    worker_data = get_worker_data(worker_id)\n",
    "\n",
    "    reject_message, reject_topic, refusal_reassons_column, measurements_translate = language_select(worker_data)\n",
    "\n",
    "    check_working_df = working_excel.loc[working_excel['assignment_id'] == assignment_cell_in_excel].loc[:,'reject_reasons':'P']\n",
    "\n",
    "    if \"+\" in check_working_df.values or 'send' in check_working_df.values:\n",
    "        assignment_link = f'https://platform.toloka.ai/requester/project/{project_id}/pool/{assignment_data.pool_id}/assignments/{assignment_id}?direction=ASC'\n",
    "        print(assignment_link)\n",
    "        if '+' in check_working_df.values:\n",
    "            print('Start sets downloading')\n",
    "            predownload_set_dublicat_checking_and_download(assignment_data, worker_id, check_working_df)\n",
    "        db_update(assignment_id, worker_id, project_id, assignment_data, worker_data, assignment_link, check_working_df)\n",
    "\n",
    "    else:\n",
    "        if str(assignment_data.status) == 'Status.SUBMITTED':\n",
    "            print('Start sets rejection')\n",
    "            reject_set(assignment_id)\n",
    "            if not 404 in check_working_df.values:\n",
    "                message_send(assignment_data, reject_message, reject_topic, worker_id, refusal_reassons_column, check_working_df, measurements_translate)\n",
    "                skill_give(assignment_id, worker_id)\n",
    "            else:\n",
    "                print('No message')\n",
    "                print('No skill')\n",
    "\n",
    "        else:\n",
    "            print('Set has another status: ', assignment_data.status, ', skip')\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "def main():\n",
    "    for assignment_id in working_excel['assignment_id'].dropna():\n",
    "        global measurements_results\n",
    "        measurements_results = measurements_results.fromkeys(measurements_results, None)\n",
    "        assignment_cell_in_excel = assignment_id\n",
    "        if 'http' in assignment_id:\n",
    "            assignment_id = get_assignment_id_from_link(assignment_id)\n",
    "        print('Processing set: ', assignment_id)\n",
    "        try:\n",
    "\n",
    "            start(assignment_id, assignment_cell_in_excel)\n",
    "\n",
    "        except toloka.exceptions.DoesNotExistApiError:\n",
    "            print(assignment_id, ' - no such set, may be it is on another account')\n",
    "        except Exception as e:\n",
    "            error_message = traceback.format_exc()\n",
    "            error_writer(f\"{assignment_id}\\t{error_message}\\n\")\n",
    "            print(assignment_id, 'error - wtite to file')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
